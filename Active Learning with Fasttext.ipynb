{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981fa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import langid\n",
    "import matplotlib.pyplot as plt\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83f2b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer, SpanishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea6e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load documents in fasttext format\n",
    "raw_train = \"C:\\\\Users\\\\Tegh\\\\fasttext\\\\amazon_reviews\\\\train.ft.txt\"\n",
    "raw_test = \"C:\\\\Users\\\\Tegh\\\\fasttext\\\\amazon_reviews\\\\test.ft.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12255e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "langid.set_languages(['en','es'])  # ISO 639-1 codes\n",
    "EngStemmer = EnglishStemmer()\n",
    "EngStops = set(stopwords.words('english'))\n",
    "\n",
    "EspStemmer = SpanishStemmer()\n",
    "EspStops = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expect precision and recall of 0.916 if all is in order for full train\n",
    "#Throwout reviews with encoding errors\n",
    "count = 0\n",
    "train = list()\n",
    "f_train = open(raw_train, 'r')\n",
    "while True:\n",
    "    try:\n",
    "        line = f_train.readline()\n",
    "        lang = langid.classify(line)[0]\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.split(\" \", 1)\n",
    "        line[1] = word_tokenize(line[1])\n",
    "        if lang == 'en':\n",
    "            line[1] = [EngStemmer.stem(w) for w in line[1] if (w.isalpha() and w not in EngStops)]\n",
    "        else:\n",
    "            line[1] = [EspStemmer.stem(w) for w in line[1] if (w.isalpha() and w not in EspStops)]\n",
    "        train.append(line)\n",
    "    except Exception as e:\n",
    "        count += 1\n",
    "        continue\n",
    "train = np.array(train, dtype = object)\n",
    "f_train.close()\n",
    "print(\"Exceptions in train set: \" + str(count))\n",
    "\n",
    "count = 0\n",
    "test = list()\n",
    "f_test = open(raw_test, 'r')\n",
    "while True:\n",
    "    try:\n",
    "        line = f_test.readline()\n",
    "        lang = langid.classify(line)[0]\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.split(\" \", 1)\n",
    "        line[1] = word_tokenize(line[1])\n",
    "        if lang == 'en':\n",
    "            line[1] = [EngStemmer.stem(w) for w in line[1] if (w.isalpha() and w not in EngStops)]\n",
    "        else:\n",
    "            line[1] = [EspStemmer.stem(w) for w in line[1] if (w.isalpha() and w not in EspStops)]\n",
    "        test.append(line)\n",
    "    except Exception as e:\n",
    "        count += 1\n",
    "        continue\n",
    "test = np.array(test, dtype = object)\n",
    "f_test.close()\n",
    "print(\"Exceptions in test set: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d51e95f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2'\n",
      " list(['stune', 'even', 'this', 'sound', 'track', 'beauti', 'it', 'paint', 'seneri', 'mind', 'well', 'i', 'would', 'recomend', 'even', 'peopl', 'hate', 'vid', 'game', 'music', 'i', 'play', 'game', 'chrono', 'cross', 'game', 'i', 'ever', 'play', 'best', 'music', 'it', 'back', 'away', 'crude', 'keyboard', 'take', 'fresher', 'step', 'grate', 'guitar', 'soul', 'orchestra', 'it', 'would', 'impress', 'anyon', 'care', 'listen'])]\n"
     ]
    }
   ],
   "source": [
    "def randSample(docs, pct_acq, pct_del = 0):\n",
    "    n = int((pct_acq + pct_del) * len(docs))\n",
    "    indices = np.random.choice(len(docs), n, replace=False)\n",
    "    return [docs[i] for i in indices]\n",
    "\n",
    "def dropout(X, Y, pct_acq, pct_del):\n",
    "    n = int(pct_acq / (pct_acq + pct_del) * len(X))\n",
    "    indices = np.random.choice(len(X), n, replace=False)\n",
    "    return [X[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675657ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y_probs):\n",
    "    return -1.0 * np.sum(y_probs * np.log(y_probs + np.finfo(float).eps)) / np.log(y_probs.size)\n",
    "    \n",
    "def least_confidence(y_probs):\n",
    "    return y_probs.size * (1 - np.nanmax(y_probs)) / (y_probs.size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81870a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext(iters, pct_acq, metric, pct_del = 0):\n",
    "    accuracy = list()\n",
    "    X = randSample(x_train, pct_acq, pct_del)\n",
    "    if pct_del > 0:\n",
    "        X = dropout(X, pct_acq, pct_del)\n",
    "    model = train_supervised('train.txt', autotuneValidationFile='valid.txt')\n",
    "    y_probs = model.predict(doc for doc in train)\n",
    "    for itr in range(iters):\n",
    "        if metric == 'LC':\n",
    "            uncertainty = pd.DataFrame([least_confidence(y) for y in y_probs]).sort_values(by = 0, ascending = False, axis = 0)\n",
    "        elif metric == 'entropy':\n",
    "            uncertainty = pd.DataFrame([entropy(y) for y in y_probs]).sort_values(by = 0, ascending = False, axis = 0)\n",
    "        n = int((pct_acq + pct_del) * len(train))\n",
    "        subX = [train[i] for i in uncertainty.iloc[:n].index.tolist()]\n",
    "        if pct_del > 0:\n",
    "            subX = dropout(subX, pct_acq, pct_del)\n",
    "        #Append lines to txt file\n",
    "        X.extend(subX)\n",
    "        model = train_supervised('train.txt', autotuneValidationFile='valid.txt')\n",
    "        y_probs = model.predict(doc for doc in train)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
